{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CentAI.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HJK-G/AI/blob/master/Colab/CentAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR0gN7zhScJZ",
        "colab_type": "text"
      },
      "source": [
        "#**CentAI**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "By Justin Kim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUWc2wzrsZvs",
        "colab_type": "text"
      },
      "source": [
        "# DESCRIPTION\n",
        "This is an AI project to play a game.\n",
        "\n",
        "It uses Deep Reinforcement Learning (DQNAgent)\n",
        "\n",
        "https://keon.io/deep-q-learning/\n",
        "\n",
        "The game is Centakill, made by one of my friends, Kaiway Tang.\n",
        "\n",
        "Go check them out at: https://kaiway.itch.io/\n",
        "\n",
        "Or just the game at: https://kaiway.itch.io/centa\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6L6bjRuoHwQ",
        "colab_type": "text"
      },
      "source": [
        "NOTE:\n",
        "\n",
        "This only works if you run this on your local machine.\n",
        "\n",
        "You can do this by:\n",
        "\n",
        "1. copying the code into a local Python environment on your computer.\n",
        "2. connecting this notebook to a local runtime\n",
        "https://research.google.com/colaboratory/local-runtimes.html\n",
        "\n",
        "I would recommend option 2 if you want to use notebooks. This allows for easier sharing and it looks cleaner. \n",
        "\n",
        "However, option 1 is probably easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y41mkdsBpaEN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "For Option 1:\n",
        "\n",
        "1. Install [Python 3.6.8](https://www.python.org/downloads/release/python-368/)\n",
        "\n",
        "2. Install [PyCharm Community Edition](https://www.jetbrains.com/pycharm/download/)\n",
        "\n",
        "3. Install [Tesseract OCR](https://github.com/tesseract-ocr/tesseract/wiki)\n",
        "\n",
        "> For Mac, use Homebrew to install.\n",
        ">\n",
        "> For Windows, use [this](https://github.com/UB-Mannheim/tesseract/wiki).\n",
        "\n",
        "4. Create a new project in PyCharm CE\n",
        "\n",
        "5. Press the dropdown menu for the Project Interpreter\n",
        "\n",
        "6. Create a new environment and select the Python that you installed for your base interpreter\n",
        "\n",
        "7. Go to your settings and find Project Interpreter. You may use the search bar. \n",
        "\n",
        "8. Find the plus button and press it to install the packages.\n",
        "\n",
        "9. Install all of the packages listed below.\n",
        "\n",
        "10. Create a new Python file\n",
        "\n",
        "11. Read the notebook and copy the code cells into the file.\n",
        "\n",
        "12. Change the score_loc and score_dim variables to fit your screen. Currently it is for a 1920 x 1080 resolution.\n",
        "\n",
        "13. For Windows, change the tesseract_path variable to the location of tesseract.exe (ex: C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe)\n",
        "\n",
        "14. Right click the file and press run.\n",
        "\n",
        "15. If prompted, give PyCharm access to your entire system. If this doesn't work, run as administrator. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FI_K2Jdpcmh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "For Option 2:\n",
        "\n",
        "This might be for more intermediate level people who want to use Jupyter Notebooks/Google Colab.\n",
        "\n",
        "1. Download Python https://www.python.org/downloads/\n",
        "\n",
        "2. Go to your terminal/command line\n",
        "\n",
        "3. Do ```pip install jupyterlab```\n",
        "\n",
        "4. Do ```pip install jupyter_http_over_ws```\n",
        "\n",
        "5. Do ```jupyter serverextension enable --py jupyter_http_over_ws```\n",
        "\n",
        "6. Do \n",
        "```\n",
        "jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com'  --port=8888 --NotebookApp.port_retries=0\n",
        "```\n",
        "to start the notebook server. This should open a new tab in your web browser.\n",
        "\n",
        "7. Go back to this notebook to the top right where it says Connect or RAM and Disk and click on the dropdown menu\n",
        "![alt text](https://cdn-images-1.medium.com/fit/t/1600/480/1*YWT1HlJeimWw61QYV4vEVA.png)\n",
        "\n",
        "8. Press connect to local runtime and then press connect\n",
        "\n",
        "9. If you close out of your terminal, you must do step 6 again to reconnect.\n",
        "\n",
        "10. Read through this notebook and run each code cell.\n",
        "\n",
        "11. It may not work the first time, because your terminal doesn't have the correct permissions. If prompted, give your terminal full control of your system (so it can press keys and take screenshots)\n",
        "\n",
        "12. It should work now. Rerun the entire thing. If you have any questions, post a comment on my Youtube video, and I'll try to help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CD0dERIlyYH",
        "colab_type": "text"
      },
      "source": [
        "#Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N24RhD4OlbY5",
        "colab_type": "text"
      },
      "source": [
        "installaton of various packages\n",
        "\n",
        "run only once at the beginning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWx6phKzlhRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy\n",
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install mss\n",
        "!pip install Pillow\n",
        "!pip install opencv-python\n",
        "!pip install pynput\n",
        "!pip install pytesseract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QamOLOnDdV-3",
        "colab_type": "text"
      },
      "source": [
        "If you are doing Option 2, run this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVrk0j4gdcQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEnsB4uDaTmB",
        "colab_type": "text"
      },
      "source": [
        "If you want to use GPU, follow these instructions:\n",
        "\n",
        "https://www.tensorflow.org/install/gpu\n",
        "\n",
        "if not, ignore the next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqRJ7w_RWGZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-gpu\n",
        "import tensorflow as tf\n",
        "print(tf.test.gpu_device_name())\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjNUFCql7Hpw",
        "colab_type": "text"
      },
      "source": [
        "imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqdMT12X7E_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from mss import mss\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from pynput.keyboard import Key, Controller\n",
        "import pytesseract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNWNe7Am4QSA",
        "colab_type": "text"
      },
      "source": [
        "This is DQNAgent. It was taken from https://keon.io/deep-q-learning/\n",
        "\n",
        "This is a class that contains the model.\n",
        "\n",
        "Tweak the values until the model learns better, these are just the default values.\n",
        "\n",
        "Every time you change this cell, you have to run the cell. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEE2d0OHv_PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=50000)\n",
        "        self.gamma = 0.95  # discount rate\n",
        "        self.epsilon = 1.0  # exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        # Neural Net for Deep-Q learning Model\n",
        "        model = Sequential()\n",
        "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(Dense(24, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mse',\n",
        "                      optimizer=Adam(lr=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values[0])  # returns action\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, min(batch_size, len(self.memory)))\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * \\\n",
        "                         np.amax(self.model.predict(next_state)[0])\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def save(self):\n",
        "        self.model.save_weights('model.h5')\n",
        "\n",
        "    def load(self):\n",
        "        self.model.load_weights('model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdPKffHmQ9xU",
        "colab_type": "text"
      },
      "source": [
        "Functions for the model to get input and interact with the computer.\n",
        "\n",
        "Run this cell once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgpMBcYvLfSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def capture_ss():\n",
        "    img = sc.grab(monitor=sc.monitors[1])\n",
        "    return np.array(Image.frombytes('RGB', img.size, img.bgra, 'raw', 'BGRX'))\n",
        "\n",
        "\n",
        "def process_img(original_img):\n",
        "    processed_img = cv2.resize(original_img, scr_dim, interpolation=cv2.INTER_AREA)\n",
        "    processed_img = cv2.cvtColor(processed_img, cv2.COLOR_BGR2GRAY)\n",
        "    return processed_img\n",
        "\n",
        "\n",
        "def shape_img(processed_img):\n",
        "    shaped_img = np.reshape(processed_img, [1, screen_size])\n",
        "    return shaped_img\n",
        "\n",
        "\n",
        "def act(action):\n",
        "    print(action)\n",
        "    if action > 4:\n",
        "        if action < 20:\n",
        "            if action % 4 == 0:\n",
        "                keyboard.press('w')\n",
        "            if action % 4 == 1:\n",
        "                keyboard.press('a')\n",
        "            if action % 4 == 2:\n",
        "                keyboard.press('s')\n",
        "            if action % 4 == 3:\n",
        "                keyboard.press('d')\n",
        "        else:\n",
        "            if action == 20 or action == 21 or action == 24 or action == 25 or action == 28 or action == 29:\n",
        "                keyboard.press('w')\n",
        "            if action == 20 or action == 22 or action == 24 or action == 26 or action == 28 or action == 30:\n",
        "                keyboard.press('a')\n",
        "            if action == 23 or action == 22 or action == 27 or action == 26 or action == 31 or action == 30:\n",
        "                keyboard.press('s')\n",
        "            if action == 23 or action == 21 or action == 27 or action == 25 or action == 31 or action == 29:\n",
        "                keyboard.press('d')\n",
        "    if action == 0 or (8 <= action <= 11) or (20 <= action <= 23):\n",
        "        keyboard.press('u')\n",
        "    if action == 1 or (12 <= action <= 15) or (24 <= action <= 27):\n",
        "        keyboard.press('i')\n",
        "    if action == 2:\n",
        "        keyboard.press('o')\n",
        "    if action == 3 or (16 <= action <= 19) or (28 <= action <= 31):\n",
        "        keyboard.press('p')\n",
        "\n",
        "\n",
        "def reset():\n",
        "    keyboard.release('w')\n",
        "    keyboard.release('a')\n",
        "    keyboard.release('s')\n",
        "    keyboard.release('d')\n",
        "    keyboard.release('u')\n",
        "    keyboard.release('i')\n",
        "    keyboard.release('o')\n",
        "    keyboard.release('p')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM4hKNfRRdgH",
        "colab_type": "text"
      },
      "source": [
        "The main function where all the AI happens.\n",
        "\n",
        "Run this once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbpxZCmhLfYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    agent = DQNAgent(screen_size, 4 + 4 + 12 + 12)\n",
        "    agent.load()\n",
        "\n",
        "    death_flag = process_img(capture_ss())[death_loc[1], death_loc[0]]\n",
        "    print(\"starting\")\n",
        "\n",
        "    time.sleep(2)\n",
        "    try:\n",
        "        # repeat episode_num times\n",
        "        for e in range(episode_num):\n",
        "            keyboard.press(Key.tab)\n",
        "            keyboard.release(Key.tab)\n",
        "\n",
        "            score = 0\n",
        "            dead = False\n",
        "            last_scr = process_img(capture_ss())\n",
        "            last_scr_vector = shape_img(last_scr)\n",
        "            action = agent.act(last_scr_vector)\n",
        "            act(action)\n",
        "            last_time = time.time()\n",
        "\n",
        "            while not dead:\n",
        "                reset()\n",
        "                screen = capture_ss()\n",
        "                pro_scr = process_img(screen)\n",
        "                scr_vector = shape_img(pro_scr)\n",
        "\n",
        "                score_crop = screen[score_loc[1]:score_loc[1] + score_dim[1],\n",
        "                             score_loc[0]:score_loc[0] + score_dim[0]]\n",
        "                score_ocr = pytesseract.image_to_string(score_crop,\n",
        "                                                        config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789')\n",
        "                if score_ocr != '':\n",
        "                    score = max(score, int(score_ocr))\n",
        "\n",
        "                death_check = pro_scr[death_loc[1]][death_loc[0]]\n",
        "                if death_flag == death_check:\n",
        "                    dead = True\n",
        "\n",
        "                reward = score\n",
        "\n",
        "                agent.remember(last_scr_vector, action, reward, scr_vector, dead)\n",
        "\n",
        "                if dead:\n",
        "                    print('episode: {}/{}, score: {}'.format(e, episode_num, reward))\n",
        "                    continue\n",
        "\n",
        "                print(time.time() - last_time)\n",
        "                last_time = time.time()\n",
        "                action = agent.act(scr_vector)\n",
        "                act(action)\n",
        "                last_scr = pro_scr\n",
        "                last_scr_vector = scr_vector\n",
        "\n",
        "            agent.replay(32)\n",
        "\n",
        "            if e % 10 == 0:\n",
        "                agent.save()\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    agent.save()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfCWKtXFRl9v",
        "colab_type": "text"
      },
      "source": [
        "This cell runs the main function. Run as many times as you want.\n",
        "\n",
        "You may need to change score_loc and score_dim to fit your computer screen. Just use trial and error to figure that out.\n",
        "\n",
        "episode_num is the number of times it will run. However, if you stop the program by pressing the stop button, the last few episodes will not be saved. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahc_gfSNa6W4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Before you run this cell, go to the game and make it full screen.\n",
        "\n",
        "Die first, but don't press tab to restart. \n",
        "\n",
        "Come back to this cell, run it, and quickly switch back to the game.\n",
        "\n",
        "Wait about 5 seconds and the AI should start playing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKTD1dlsRw8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytesseract.pytesseract.tesseract_cmd = r'full_path_to_your_tesseract_executable'\n",
        "\n",
        "keyboard = Controller()\n",
        "sc = mss()\n",
        "\n",
        "episode_num = 160\n",
        "scr_dim = (200, 50)\n",
        "score_loc = (1085, 150)  # x, y\n",
        "score_dim = (400, 165)  # x, y\n",
        "death_loc = (int(scr_dim[0] / 2), int(scr_dim[1] / 2))\n",
        "screen_size = scr_dim[0] * scr_dim[1]\n",
        "\n",
        "time.sleep(4)\n",
        "main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ84YZHxvtC_",
        "colab_type": "text"
      },
      "source": [
        "Score location testing code:\n",
        "\n",
        "Run this to use trial and error to determine the location of your score. \n",
        "\n",
        "It should then create a new window where it shows what part of the screen it grabbed. \n",
        "\n",
        "Press q to quit that screen and continue to modify the location and dimensions if they are wrong. \n",
        "\n",
        "Remember, it should contain all digits of the score, and no rocks or anything.\n",
        "\n",
        "---\n",
        "\n",
        "If you are doing this in a local Python environment (Option 1), create a new file and put this code inside that.\n",
        "\n",
        "If you are doing this on Colab with a local runtime (Option 2), run only this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ELAId3arDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from mss import mss\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "\n",
        "def capture_ss():\n",
        "    img = sc.grab(monitor=sc.monitors[1])\n",
        "    return np.array(Image.frombytes('RGB', img.size, img.bgra, 'raw', 'BGRX'))\n",
        "\n",
        "\n",
        "score_loc = (1085, 150)  # x, y\n",
        "score_dim = (400, 165)  # x, y\n",
        "# pytesseract.pytesseract.tesseract_cmd = r'full_path_to_your_tesseract_executable'    # remember to change this variable if you are on a local Python environment and on Windows\n",
        "\n",
        "sc = mss()\n",
        "\n",
        "time.sleep(4)\n",
        "\n",
        "screen = capture_ss()\n",
        "\n",
        "score_crop = screen[score_loc[1]:score_loc[1] + score_dim[1],\n",
        "             score_loc[0]:score_loc[0] + score_dim[0]]\n",
        "score_ocr = pytesseract.image_to_string(score_crop,\n",
        "                                        config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789')\n",
        "if score_ocr != '':\n",
        "    print(int(score_ocr))\n",
        "\n",
        "while True:\n",
        "    cv2.imshow('press q to stop', score_crop)\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        cv2.destroyAllWindows()\n",
        "        break\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}